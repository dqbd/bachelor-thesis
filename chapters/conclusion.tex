\chapter{Conclusion}\label{chapter:conclusion}

\section{Goals and results}
The goal of this body of work was to study and understand the B-Tree data structure with all of its variants and introduce an implementation of a B-Tree data structure capable of execution on the GPU.

Core concepts behind the CUDA programming model were studied and explained; how it allows the programmer to execute GPU code from the CPU, how threads are organized and assigned to each CUDA execution core, and how a programmer can synchronize threads on the GPU. An introduction to the Template Numerical Library has been made to understand how template metaprogramming can provide a unified interface for different execution environments.

Two variants of B-Tree were introduced and described: B$^+$Tree and B-Link-Tree. Both of the variants were appropriately modified to support concurrent updates and reads. All of the implementations were written in \CC\ with the help of the TNL library.

The principles behind the Warp Cooperative Work Sharing strategy were outlined, and different warp-friendly optimizations were introduced to utilize the entire warp to accelerate a single operation, avoiding unnecessary warp divergence and improving performance. Proactive splitting has been utilized to avoid implementing a stack for keeping track of parent nodes, and various concurrency control methods used in both of the variants were discussed.

Multiple GoogleTest based unit test suites were written to ensure proper functionality. A complementary web tool has been developed to visualize operations done in a multithreaded environment.

Finally, both of the implementations were measured and compared against STL and other state-of-the-art GPU and CPU B-Tree implementations. Measurements of both variants against \codecpp{std::map} show a substantial speedup: $\approx$\,$200\times$ when querying and $\approx$\,$25\times$ when inserting random sequences of length $2^{24}$--$2^{25}$. When compared to the GPU B-Tree implementation by Awad et al. \cite{awad}, both of the variants implemented in this thesis are slower. It should be noted that both the B$^+$Tree and B-Link-Tree perform similarly, suggesting the reduced instruction count and reduced unnecessary pointer chasing in B$^+$Tree overshadow the concurrency improvements of B-Link-Tree.

\section{Future work}

The implementation presented in this thesis, as shown in \cref{section:results}, is $\approx$\,$3\times$ slower than the solution from Awad et al. \cite{awad}, even though it is not certain their implementation perform correctly on large input sequences. Further work needs to be done to improve memory access patterns. Another point of improvement can be the implementation of range queries.