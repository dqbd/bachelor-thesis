\section{Latching and Concurrency Control}

For our implementation of B-Trees, an additional attribute $x.writelock$ is used to prevent multiple threads from writing to the same node at the same time.

In the B$^+$Tree implementation of insertion, traversal is prevented if encountering a node with a write lock to ensure data serializability, as the node with a lock is most likely not in a correct state and may lead the traversal operation to an incorrect subtree. Thus, to solve this issue, the search is restarted from the start if reaching a node with a lock, sharing the properties of a back-off lock.

B-Link-Tree has this limitation lifted, as the tree is always traversable, even if the node is locked for writing. As described in \cref{section:b-link-tree}, each node has a $x.sibling$ pointer referencing next at the same depth. At every depth, the nodes are essentially chained in a linked list. With this addition, a correct node is always found with the help of the additional path to reach every node.

In both of the implementations, \code{warp.sync()} and \code{\_\_threadfence()} is sporadically needed to ensure correct order of instructions used for memory access.

Latching itself is done by a \code{BNodeLatch} class. This class does include two separate template specializations, with the CUDA specialization utilizing atomic instructions such as \code{atomicAdd} and \code{atomicCAS} to avoid serializability issues when acquiring or releasing a latch. Host specialization does not require a critical section, as the implementation runs on a single thread. The class is not explicitly bound to any of the B-Tree implementations, and a template class of a node must be provided when instantiating the latch. 