\section{Environment}

The measurements are captured on the \code{gp1} system provided by Faculty of Nuclear Sciences and Physical Engineering, Czech Technical University with following specifications \ref{table:env-gp1}:

\begin{table}[H]
  \centering
  \begin{tabular}{ | l | l | }
    \hline
    CPU             & Intel Xeon CPU E5-2630 v3 (2.40\,GHz)    \\
    \hline
    GPU             & NVIDIA Quadro P6000 (24\,GB, CUDA 6.1)   \\
    \hline
    RAM             & 128\,GB                                  \\
    \hline
    Driver          & 465.31                                   \\
    \hline
    OS              & Arch Linux (kernel 4.12.9, KPTI enabled) \\
    \hline
    Host compiler   & GCC g++ 11.1.0                           \\
    \hline
    Device compiler & nvcc v11.3.58                            \\
    \hline
  \end{tabular}
  \caption{Hardware and software specification of the \code{gp1} system.}
  \label{table:env-gp1}
\end{table}

As for the compilation itself, optimalization flag is set to \code{-O3}.  \CC\,dialect is set to \CC17 when benchmarking against different implementations, although \CC14 is supported as well.

\section{Testing methodology}

As the execution of code on device is not deterministic, it is hard to prove complete absence of errors and bugs of the solution. Nevertheless, for each of the B-Tree implementations a set of unit tests is prepared. These unit tests rigorously examine if each operation preserves the valid tree state, which has proved to be helpful when optimizing the performance of the tree without sacrificing correctness. \code{GoogleTest} framework \cite{gtest} is the framework of choice used for writing these unit test suites.

For the host implementation, unit tests do include assertions of internal states of a node to aid the development and catch bugs early on. On the device side though, assertions on the device code are limited and unit tests make their assertions only on the result after operation completion. \code{GoogleTest} is unfortunately not supported on the device code.

To better understand the behavior of operations done on a GPU B-Tree, a complementary web-based visual debugger \ref{figure:debugger} has been developed, which takes the logs from standard output enabled by a flag as the input and render the state of the tree visually. Finding bugs and concurrency issues is significantly easier with the aid of the visual debugger.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{components/figure/debugger.png}
  \caption{Web based visual debugger displaying the internal state of a tree.}
  \label{figure:debugger}
\end{figure}

In the case of multiple B-Tree variants, to avoid duplicating tests and ensure correctness of both of the implementations, typed tests are used to repeat the same logic over a list of types \cite{gtest-advanced}, as seen in Listing \ref{lst:gtest-typed}. The \code{typename} of each class will be available as a static field within \code{TestFixture} itself.

\begin{listing}
  \begin{minted}{cpp}
template <typename C> class TestSuite : public testing::Test {
public:
  using Implementation = C;
};

using TypeList = ::testing::Types<A, B>;
TYPED_TEST_SUITE(TestSuite, TypeList);

TYPED_TEST(TestSuite, Test) {
  typename TestFixture::Implementation impl;
  // ... rest of test implementation
}
    \end{minted}
  \caption{Snippet of a \code{GoogleTest} typed test}\label{lst:gtest-typed}
\end{listing}

\section{Benchmarking methodology}

After measuring execution times from chosen implementations, we calculate the speedup as the ratio of serial execution time on the CPU and parallel execution time on the GPU.

$$\mathit{Speedup} = \frac{\tau_{\mathit{CPU}}}{\tau_{\mathit{GPU}}}$$

\section{Numerical network microbenchmark}

\todo{Add numerical mesh microbenchmark - numerical networks}

To determine the performance speedup between the GPU and the CPU implementation, a micro-benchmark is introduced with a simple use case. The benchmark consists of incremental inserting and querying unstructured numerical cube mesh.

\section{Comparison against known implementations}

This section describes the comparison of the thesis implementation against other GPU and CPU based implementations. \todo{add cites}

For all of the experiments, 32-bit keys and values are used. Different kinds of pair sequences were used as the input data and each implementation is executed and measured 10 times. Results presented here are averaged. Measurement of CPU based variants are measured using {std::chrono::high\_resolution\_clock::now}, whereas the GPU based ones are measured using CUDA runtime API. The time spent on copying the data from host to device is not included in the measurement.

\todo{Add search benchmark}

\todo{Add insertion benchmark}

\todo{Add an explanation why \cite{awad} is 2-3 times faster than our implementation.} Improved memory access